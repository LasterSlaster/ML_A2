{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 4: Supportvektormaschinen mit Scikit Learn, Random Forests und Boosting\n",
    "\n",
    "### 1. Klassifikation mit SVMs\n",
    "\n",
    "a. Laden Sie, wie im Tutorium beschrieben, den berühmten MNIST-Datensatz mit eingescannten handgeschriebenen Ziffern mit der Funktion digits = load_digits(). Wie in Übung 1 gelernt, finden Sie heraus,\n",
    "wieviele und welche Labels und wieviele Daten es gibt, und welche Dimension diese haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "digits = datasets.load_digits()\n",
    "print(\"digits.data:\")\n",
    "print(digits.data)\n",
    "print(\"Dimensionen von digits.data:\")\n",
    "print(digits.data.shape)\n",
    "print(\"digits.target:\")\n",
    "print(digits.target)\n",
    "print(\"Es gibt so viele Bilder:\",len(digits.images))\n",
    "print(\"Jedes Bild besteht aus\",digits.data[1].shape, \" Pixeln.\")\n",
    "#Grundlegende Informationen zum Datensatz:\n",
    "#digits.DESCR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen Sie eine Zufallsauswahl von 10 Bildern (zusammen mit der Klassenzugehörigkeit) in\n",
    "Ihrem Notebook dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "for i  in range(10):\n",
    "    plt.figure(1, figsize=(3, 3))\n",
    "    r=random.randrange(1, len(digits.images)-1)\n",
    "    plt.imshow(digits.images[r], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "    print(digits.target[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Teilen Sie den Datensatz zufällig in einen nichtüberlappenden Trainings- und Testdatensatz\n",
    "auf, so dass ein Viertel der Daten zu Testdaten werden. Dies geschieht am Einfachsten\n",
    "mit der Funktion sklearn.model_selection.train_test_split(). Trainieren Sie einen\n",
    "Supportvektor-Klassifikator (Standard in Scikit Learn ist eine 1-Norm Soft Margin SVM, bei\n",
    "Mehrklassenproblemen wird automatisch ein Satz von one-vs.-one-Klassifikatoren erstellt)\n",
    "mit einem RBF-Kern mit \n",
    " gamma= 0.015 und einem Parameter C = 1.0. Bestimmen Sie den\n",
    "Anteil korrekt klassifizierter Beispiele (Korrektklassifikationsrate, Treffergenauigkeit, engl.\n",
    "Accuracy) im Trainings- und Testdatensatz mithilfe der Funktion SVC.score(). Underfitting\n",
    "liegt vor, wenn Ihr Klassifikator auf den Trainingsdatensatz eine Treffergenauigkeit von\n",
    "deutlich unter 100% erzielt, bei Overfitting liegt die Treffergenauigkeit auf dem Testdatensatz\n",
    "deutlich unter der auf dem Trainingsdatensatz. Welcher Fall liegt hier vor?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "#clf (=classifier) wird erstellt\n",
    "clf = svm.SVC(gamma=0.015, C=1.0)\n",
    "#durch fit wird dieser trainiert\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit gamma= 0.015 und einem Parameter C = 1.0 ist die Treffergenauigkeit auf dem\n",
    "Trainingsdatensatz bei 100% und die Treffergenauigkeit auf dem Testdatensatz ist deutlich darunter.\n",
    "--> hier liegt also Overfitting vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probieren\n",
    "Sie alternativ die SVM-Parameter \n",
    "gamma = 0.001 und C = 100 und vergleichen Sie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei gamma = 0.001 und C = 100 ist das Ergebnis viel besser. Die Treffergenauigkeit auf dem\n",
    "Trainingsdatensatz ist bei 100% und die Treffergenauigkeit auf dem Testdatensatz mit 99,3 sehr hoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiederholen\n",
    "Sie das Experiment für einen anderen Zufallssplit in Trainings- und Testdatensatz. Wie stark\n",
    "hängt Ihr Ergebnis von der zufälligen Teilung in Trainings- und Testdatensatz ab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hängt bei ersten SVM-Paramtern stärker von Zufallssplit ab. Bei zweitem Szenario der SMV-Paramter hängt es kaum vom Zufallssplit ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kreuzvalidierung und Modellselektion\n",
    "\n",
    "a. Bei der Methode der Kreuzvalidierung wird der zufällige Split in Trainings- und Testdatensatz aus Aufgabe 1 mehrere Male wiederholt und der Durchschnitt über mehrere Splits berechnet, um eine genauere Schätzung der wirklichen Treffergenauigkeit zu erhalten. Scikit Learn\n",
    "stellt dafür bereits eine vordefinierte Methode zur Verfügung: sklearn.model_selection.\n",
    "ShuffleSplit(). Die Methode verwendet die Iteratorsyntax von Python, Beispiele zur\n",
    "Verwendung finden Sie in der Dokumentation dieser Methode. ShuffleSplit() erzeugt\n",
    "einen Satz von permutierten Indizes von Trainings- und Testdaten. Erzeugen Sie zunächst 3\n",
    "Sätze und trainieren Sie für jeden Satz eine SVM mit γ = 0.001 und C = 1 und geben Sie\n",
    "jeweils die Treffergenauigkeit für Trainings- und Testdatensatz aus. Die Ergebnisse sollten\n",
    "ähnlich wie in Aufgabe 1b aussehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "X_train=[];\n",
    "X_test=[];\n",
    "y_train=[];\n",
    "y_test=[];\n",
    "for train_index, test_index in rs.split(digits.data):\n",
    "    \n",
    "    for i in train_index:\n",
    "        X_train.append(digits.data[i])\n",
    "        y_train.append(digits.target[i])\n",
    "    for i in test_index:\n",
    "        X_test.append(digits.data[i])\n",
    "        y_test.append(digits.target[i])\n",
    "        \n",
    "    clf = svm.SVC(gamma=0.001, C=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
