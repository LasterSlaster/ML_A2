{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','TGT']\n",
    "boston = pd.read_csv(url,sep=' ',skipinitialspace=True,header=None,names=cols,index_col=False)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(df, r):\n",
    "    centered = df - df.mean(axis=0)\n",
    "    normalized = centered / centered.std(axis=0)\n",
    "    \n",
    "    matrix = normalized.values\n",
    "    \n",
    "    u, d, vt = np.linalg.svd(matrix, full_matrices=False)\n",
    "    v = vt.transpose()\n",
    "    \n",
    "    n, m = df.shape\n",
    "    ud = u * d\n",
    "    pc = []\n",
    "    ai = []\n",
    "    \n",
    "    for ri in range(r):\n",
    "        pc.append(v[:,ri])\n",
    "        ai.append(ud[:,ri])\n",
    "    # pow of 2 because we need variance which is stdd^2\n",
    "    return pc,ai,np.power(d, 2)/(n-1), df.mean(axis=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pc: Principal Components, ai: Projections, qsd:Eigenvalues\n",
    "pc, ai, qsd, means =  pca(boston,boston.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(columns=[\"EW\", \"EXP_VAR\", \"KUM_VAR\"])\n",
    "sumv = np.sum(qsd)\n",
    "kumvar = 0\n",
    "for i in range(14):\n",
    "    expvar = qsd[i] / sumv\n",
    "    kumvar = kumvar + expvar\n",
    "    table = table.append({'EW':qsd[i], 'EXP_VAR': expvar,'KUM_VAR': kumvar}, ignore_index=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wieviele Dimensionen können Sie weglassen, wenn Sie 10%, 5% und 1% Fehler bei der Dimensionsreduktion zulassen?\n",
    "- 10% : 6\n",
    "- 5%  : 4\n",
    "- 1%  : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered = boston - boston.mean(axis=0)\n",
    "normalized = centered / centered.std(axis=0)\n",
    "variables = normalized.values\n",
    "\n",
    "matrix = np.zeros((3, np.shape(variables)[1]))\n",
    "for i in range(3):\n",
    "    for j in range(np.shape(variables)[1]):\n",
    "        matrix[i][j] = np.corrcoef(ai[i], variables[:,j])[0,1]\n",
    "\n",
    "pd.DataFrame.from_records(matrix.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis auf die vierte Variable werden alle Variablen gut von der ersten Hauptkomponente dargestellt, da die Zahlen recht hoch sind. Diese Variable wird allerdings von der zweiten Hauptkomponente gut dargestellt. Mit den ersten drei Hauptkomponenten werden alle Variablen gut dargestellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(ai[0:2]).transpose()\n",
    "plt.scatter(df[0],df[1], color=np.where(boston['TGT'] >= boston['TGT'].describe()['50%'], 'b', 'r'))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die beiden neuen Variablen eignen sich nur bedingt, da sich die beiden Datenwoklen überschneiden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import skimage.io as io\n",
    "import skimage.transform as tsf\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"D:/HTWG/MSI/Semester1/Machine Learning/Aufgaben/lfw-funneled.tgz\")\n",
    "popular = []\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.isdir():\n",
    "        person = tarinfo.name\n",
    "        i = 0\n",
    "    elif tarinfo.isreg() and tarinfo.name.endswith(\"jpg\"):\n",
    "        i += 1\n",
    "    if i >= 70:\n",
    "        if person not in popular:\n",
    "            popular.append(person)\n",
    "            print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_name = \"\"\n",
    "t_imgs = []\n",
    "imgs = []\n",
    "names = []\n",
    "t_names = []\n",
    "\n",
    "\n",
    "for tarinfo in tar:\n",
    "    if tarinfo.isreg() and tarinfo.name.endswith(\"jpg\") and tarinfo.name.split(\"/\")[0] + \"/\" + tarinfo.name.split(\"/\")[1] in popular:        \n",
    "        img = io.imread(\"D:/HTWG/MSI/Semester1/Machine Learning/Aufgaben/\" + tarinfo.name, as_gray=True)[75:175, 75:175]\n",
    "        img = tsf.rescale(img, 0.32, anti_aliasing=False, multichannel=False)\n",
    "        img = img.flatten()\n",
    "        if (tarinfo.name.split(\"/\")[1] != p_name):\n",
    "            t_imgs.append(img)\n",
    "            t_names.append(tarinfo.name.split(\"/\")[1])\n",
    "            p_name = tarinfo.name.split(\"/\")[1]\n",
    "        else:\n",
    "            imgs.append(img)\n",
    "            p_name = tarinfo.name.split(\"/\")[1]\n",
    "            names.append(tarinfo.name.split(\"/\")[1])\n",
    "        #print(tarinfo.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(t_imgs))\n",
    "print(len(imgs))\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_data = pd.DataFrame(imgs)\n",
    "t_imgs_data = pd.DataFrame(t_imgs)\n",
    "\n",
    "#pc: Principal Components, ai: Projections, qsd:Eigenvalues\n",
    "pc, ai, qsd, means =  pca(imgs_data, 150)\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qsd[:150], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = []\n",
    "i = 0\n",
    "for g in pc:\n",
    "    eg.append(np.resize(g, (32,32)))\n",
    "    i += 1\n",
    "    if i == 12:\n",
    "        break\n",
    "        \n",
    "test = io.imshow_collection(eg, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test = t_imgs_data - imgs_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distances = []\n",
    "for index, test_picture in centered_test.iterrows():\n",
    "    dst = []\n",
    "    for g in eg[0:7]:\n",
    "        d = distance.euclidean(np.array(test_picture), g.flatten())\n",
    "        dst.append(d)\n",
    "    distances.append(dst)\n",
    "\n",
    "for i in range(len(distances)):\n",
    "    d = distances[i]\n",
    "    io.imshow\n",
    "    print(t_names[i] + \"/\" + names[d.index(min(d))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(7):\n",
    "    dist = []\n",
    "    for x in eg:\n",
    "        dist.append(np.linalg.norm(x.flatten() - np.array(centered_test[n])))\n",
    "\n",
    "    min_val = 99999999999\n",
    "    min_val_idx = -1\n",
    "    for i, v in enumerate(dist):\n",
    "        if min_val > v:\n",
    "            min_val = v\n",
    "            min_val_idx = i\n",
    "\n",
    "    idx = -1\n",
    "    cumsum = 0\n",
    "    while cumsum < min_val_idx:\n",
    "        idx += 1\n",
    "        cumsum += len(imgs[idx])\n",
    "\n",
    "    print(\"Test image \" + str(n + 1) + \" (label/classified): \" + names[n] + \"/\" + names[idx] + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
