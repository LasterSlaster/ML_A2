{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIolRLmR2tJc"
   },
   "source": [
    "# Linear Regression on Fish Data\n",
    "\n",
    "The following data-set contains the number of fish groups of camper caught in a state park (taken from https://stats.idre.ucla.edu/r/dae/zip/). Your task here is to predict the number of fish caught by a fishing party from the following information: \n",
    "\n",
    "* how many people are in the group\n",
    "* the number children in the group\n",
    "* the use of live bait\n",
    "* whether the group came with a camper to the park. \n",
    "\n",
    "We have a small data set, of 250 groups, which visited a state park and provided. For comparison the data set is already split into a training set and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsAt_vDL3jFG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FQJjRm32sVc"
   },
   "outputs": [],
   "source": [
    "# The Fish Data Set\n",
    "# See example 2 from https://stats.idre.ucla.edu/r/dae/zip/ \n",
    "#\"nofish\",\"livebait\",\"camper\",\"persons\",\"child\",\"xb\",\"zg\",\"count\"\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.isfile('fishing.npz'):\n",
    "    print(\"Downloading\")\n",
    "    urlretrieve('http://www-home.htwg-konstanz.de/~oduerr/data/fishing.npz',filename = 'fishing.npz')\n",
    "d = np.load('fishing.npz')\n",
    "Xt = d['Xt'] #\"livebait\",\"camper\",\"persons\",\"child\"\n",
    "Xte = d['Xte']\n",
    "yt = d['yt']\n",
    "yte = d['yte']\n",
    "pd.DataFrame(Xt[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIaw-4LgK0zz"
   },
   "source": [
    "a) Do a linear regression by creating a design matrix with the intercept term and use the fomulae given in the lecture to determine the coefficients on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new = np.concatenate((Xt.T, np.ones((1,200))))\n",
    "Xt_new = Xt_new.T\n",
    "print(Xt_new.shape)\n",
    "Xte_new = np.concatenate((Xte.T, np.ones((1,50))))\n",
    "Xte_new = Xte_new.T\n",
    "print(Xte_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_new[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.asmatrix(Xt_new)\n",
    "Xte = np.asmatrix(Xte_new)\n",
    "yt = np.asmatrix(yt).T\n",
    "print(Xt[0:3])\n",
    "Xt.shape, yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones((5))\n",
    "print(w)\n",
    "d = np.matmul(Xt,w)\n",
    "d[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTX = np.matmul(Xt.T,Xt)\n",
    "XTXI = np.linalg.inv(XTX)\n",
    "XTXIXT = np.matmul(XTXI, Xt.T)\n",
    "w = np.matmul(XTXIXT,yt)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.square((np.matmul(Xt,w).flatten() - yt.flatten()))) # The MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.shape, w.shape\n",
    "np.mean(np.square((np.matmul(Xte,w).flatten() - yte.flatten()))) # The MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.matmul(Xte,w)\n",
    "y_pred = np.squeeze(np.asarray(y_pred))\n",
    "\n",
    "plt.scatter([y_pred], [yte])\n",
    "plt.xlabel('Predicted Fish Caught')\n",
    "plt.ylabel('True Fish Caught')\n",
    "\n",
    "\n",
    "MSE = np.mean(np.square((y_pred - yte))) # The MSE\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-uaG92sPBXg"
   },
   "source": [
    "b) Repeat a) but this time with `LinearRegression` from `sklearn.linear_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_skl = LinearRegression(fit_intercept=False) #We have an extended X\n",
    "model_skl.fit(Xt,yt)\n",
    "model_skl.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.matmul(Xte,w)\n",
    "plt.scatter([y_pred], [yte])\n",
    "plt.xlabel('Predicted Fish Caught')\n",
    "plt.ylabel('True Fish Caught')\n",
    "\n",
    "np.mean(np.square((y_pred - yte))) # The MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: array([-8.49222821,  2.4822138 ,  2.95430727,  4.64953914, -5.47160051])\n",
    "Don't forget the intercept, you should have 5 numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNIUUugxPmSZ"
   },
   "source": [
    "c) Determine the Root Mean Square Error (RMSE) and the average negative log-likelihood (NLL) on the testset. For NLL we assume that the conditional probability distrubution (CPD) $p(y|x)$ is given by the density of a Gaussian with constant variance $\\sigma^2$. Estimate $\\sigma^2$ using the variance of the residuals. Use the variance estimation with $1/N$. \n",
    "\n",
    "Result: $ RMSE \\approx 8.58812$, $\\hat \\sigma^2 \\approx 73.7559$, $\\tt{NLL} \\approx 3.569$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "print(\"RMSE:\", math.sqrt(MSE))\n",
    "#print(\"SIGMA^2:\", np.mean((y_pred - yte)**2))\n",
    "#print(\"SIGMA^2:\", np.mean(np.square((y_pred - yte))))\n",
    "print(\"SIGMA^2:\", MSE)\n",
    "\n",
    "\n",
    "\n",
    "#var = mean(abs(x - x.mean())**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCJHxadORefq"
   },
   "source": [
    "d) For the testset: plot the predicted mean number of fish caught ($\\mu$) against observed number of fish caught. Further include the 2.5 and 97.5 precentile of p(y|x), the conditional predictive distribution (CPD) of $y$ for a given $x$. Why is a Gaussian not ideal for that kind of data? \n",
    "\n",
    "Hint: For the Gaussian the 2.5% and the 97.5% percentile is approximatiy given by $\\mu \\pm 1.96*\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = y_pred, columns = [\"y_pred\"])\n",
    "\n",
    "df.insert(loc = 1, column = \"y_te\", value = yte)\n",
    "\n",
    "display(df.head())\n",
    "display(df.describe(percentiles=[0.025, .25, .5, .75, 0.975]))\n",
    "\n",
    "def percentile(mean, sigma):\n",
    "    percentile_025 = mean - 1.96 * sigma\n",
    "    percentile_975 = mean + 1.96 * sigma\n",
    "    return percentile_025, percentile_975\n",
    "\n",
    "y_pred_perc = percentile(3.584987, 4.624718)\n",
    "y_te_perc = percentile(3.060000, 10.222845)\n",
    "\n",
    "y_pred_perc, y_te_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wo5FcZ_VHIw"
   },
   "source": [
    "e) This data is count data. Count data has only positive values and also the distribution is discrete. You cannot catch 0.5 fish and that the CPD has probability density > 0 on negative number of fish is wrong too. A Gaussian as a CPD is therefore not ideal. \n",
    "\n",
    "Now use a Poissonian as CPD. If we assume a Poissonian then the probability to catch $k$ fish is given by \n",
    "$$\n",
    "  p(k) = \\exp(-\\mu) \\frac{\\mu^k}{k!}\n",
    "$$\n",
    "\n",
    "and the NLL is thus by:\n",
    "\n",
    "$$\n",
    " log(p(k)) = -\\mu  + k \\cdot \\log(\\mu) - log(k!)\n",
    "$$\n",
    "\n",
    "with $\\mu$ being the expectation. In our case the average number of fish expected.\n",
    "\n",
    "In the case of the probabilistic interpretation of the linear regression, $y_i$ for a given $x_i$ is distributed like a Gaussian. The paramter $\\mu_i$ from $N(\\mu_i,\\sigma^2)$ has been determined from $x_i$ via $\\mu_i= \\beta^T \\cdot x_i$ by minimizing the NLL. \n",
    "\n",
    "A small additional detail: For the Poissonian case, $\\mu_i$ needs to be positive. We therefore do not use $\\beta^T \\cdot x_i$ directly but \"pipe it through\" an exponential first to make it positive and thus link $\\mu_i=exp(\\beta^T \\cdot x_i)$ to the data.\n",
    "\n",
    "Use a gradient descent approach on the NLL to find the solution for the parameters. Calculate the RMSE and the NLL on the test set and compare with c).\n",
    "\n",
    "Hint: On the trainingset for the parameter values (1,1,1,1,1) the NLL should be approx 1508 and the gradient (1518.61, 1403.99, 1171.02, 5701.91, 3258.7). For the NLL a good learning rate would be 0.001 and training should be done for at least 5000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL(y_train, Xd, w):\n",
    "    mu = np.exp(np.matmul(Xd,w))\n",
    "    ret = np.zeros_like(mu)\n",
    "    for i in range(ret.shape[0]):\n",
    "        ret[i] = mu[i] - y_train[i]*np.log(mu[i]) + np.log(1.0*np.math.factorial(y_train[i]))\n",
    "    return np.mean(ret)\n",
    "\n",
    "w = np.ones(5)\n",
    "yt_arr = np.squeeze(np.asarray(yt))\n",
    "yt_arr = yt_arr.astype(int)\n",
    "Xt_arr = np.squeeze(np.asarray(Xt))\n",
    "\n",
    "NLL(yt_arr, Xt_arr, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradNLL(y_train, Xd, w):\n",
    "    mu = np.exp(np.matmul(Xd,w))\n",
    "    #print(mu.shape)\n",
    "    ret = np.zeros_like(Xd)\n",
    "    for i in range(Xd.shape[0]):\n",
    "        mux = Xd[i] * mu[i]\n",
    "        ret[i] = -mux + y_train[i] *Xd[i]\n",
    "    return np.mean(ret, axis=0)\n",
    "\n",
    "NLL(yt_arr, Xt_arr,np.ones(5))\n",
    "np.round(gradNLL(yt_arr, Xt_arr,np.ones(5)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "w = np.ones(5)\n",
    "hist = []\n",
    "for i in tqdm(range(10000)):\n",
    "    if (i % 10 == 0):\n",
    "        hist.append(NLL(yt_arr, Xt_arr,w))\n",
    "    w = w + 0.001 * gradNLL(yt_arr, Xt_arr,w)\n",
    "w, NLL(yt_arr, Xt_arr,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist)\n",
    "plt.ylim(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Do the same plot as in d) but this time with a Poisson CPD. Hint you can use scipy.stats.poisson to calculate the percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Linear_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
